{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.9.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.6 64-bit"
    },
    "interpreter": {
      "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
    },
    "colab": {
      "name": "Lecture_9_Image_warping_Panorama.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/jbinteam/010723305/blob/main/Homework9p2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install  opencv-contrib-python==4.5.3.56\r\n",
        "import numpy as np\r\n",
        "import cv2 \r\n",
        "import scipy\r\n",
        "import matplotlib.pylab as plt\r\n",
        "from skimage import io"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOBSUACuAO46",
        "outputId": "505ef385-a17e-4576-ab13-215036eeb504"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 style = \"text-align: center\">Custom implementation: numpy + scipy + opencv</h1>"
      ],
      "metadata": {
        "id": "onx3-ondAO4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 style = \"text-align: center\"> Homogenous coordinate</h1>\n",
        "\n",
        "<h2 style = \"text-align: center\">\n",
        "\n",
        "$$ \n",
        "x = \\left[ \\begin{matrix} x\\\\y \\end{matrix}\\right] \\rightarrow \\overline{x} =  \\left[ \\begin{matrix} ax\\\\ay\\\\a \\end{matrix} \\right] = a \\left[ \\begin{matrix} x\\\\y\\\\1\\end{matrix} \\right]\n",
        "$$\n",
        "\n",
        "</h2>"
      ],
      "metadata": {
        "id": "Z7xF2OltAO5B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def imshow_compare(img1, img2) :\r\n",
        "    fig, axes = plt.subplots(1,2, figsize = (20,20))\r\n",
        "    axes[0].imshow(img1)\r\n",
        "    axes[1].imshow(img2)"
      ],
      "outputs": [],
      "metadata": {
        "id": "szOEFPRrAO5D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def normalize(points) :\r\n",
        "    \"\"\" Normalize points, so divide points with the last one\"\"\"\r\n",
        "    for row in points :\r\n",
        "        row /= points[-1]\r\n",
        "    return points"
      ],
      "outputs": [],
      "metadata": {
        "id": "F-eYW2DeAO5E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def make_homogeneous(points) :\r\n",
        "    \"\"\"Convert heterogenous to homogenous coordinate\"\"\"\r\n",
        "    return np.vstack((points, np.ones((1,points.shape[1])))) #stacking the last coordinate with one"
      ],
      "outputs": [],
      "metadata": {
        "id": "HCppY3kkAO5E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 style = \"text-align: center\">\n",
        "Affine matrix from point set\n",
        "</h1>\n",
        "\n",
        "<h2 style = \"text-align: center\">\n",
        "\n",
        "$$\n",
        "    Ma=b, a= \\left( M^{T}M \\right)^{-1} M^T b\n",
        "$$\n",
        "\n",
        "$$\n",
        "    \\left[\n",
        "        \\begin{matrix}\n",
        "            m_{x1}&&m_{y1}&&1&&0&&0&&0\\\\\n",
        "            0&&0&&0&&m_{x1}&&m_{y1}&&1\\\\\n",
        "            m_{x2}&&m_{y2}&&1&&0&&0&&0\\\\\n",
        "            0&&0&&0&&m_{x2}&&m_{y2}&&1\\\\\n",
        "            m_{x3}&&m_{y3}&&1&&0&&0&&0\\\\\n",
        "            0&&0&&0&&m_{x3}&&m_{y3}&&1\\\\\n",
        "        \\end{matrix}\n",
        "    \\right]\n",
        "    \\left[\n",
        "        \\begin{matrix}\n",
        "            a_{00}\\\\\n",
        "            a_{01}\\\\\n",
        "            a_{02}\\\\\n",
        "            a_{10}\\\\\n",
        "            a_{11}\\\\\n",
        "            a_{12}\n",
        "        \\end{matrix}\n",
        "    \\right]\n",
        "    =\n",
        "    \\left[\n",
        "        \\begin{matrix}\n",
        "            n_{x1}\\\\\n",
        "            n_{y1}\\\\\n",
        "            n_{x2}\\\\\n",
        "            n_{y2}\\\\\n",
        "            n_{x3}\\\\\n",
        "            n_{y3}\n",
        "        \\end{matrix}\n",
        "    \\right]\n",
        "$$\n",
        "\n",
        "</h2>"
      ],
      "metadata": {
        "id": "OrKEzIt6AO5F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def Haffine_from_points(fp, tp) :\r\n",
        "    \"\"\"Find affine matrix tp(n) is affine transform of fp(m)\"\"\"\r\n",
        "\r\n",
        "    if fp.shape != tp.shape :\r\n",
        "        raise RuntimeError('Number of points do not match')\r\n",
        "\r\n",
        "    # Preconditioning points -> normalization, standardization\r\n",
        "    # from points (m points)\r\n",
        "    m = np.mean(fp[:2], axis=1)\r\n",
        "    maxstd = max(np.std(fp[:2], axis=1)) + 1e-9\r\n",
        "    C1 = np.diag([1/maxstd, 1/maxstd, 1])\r\n",
        "    C1[0][2] = -m[0]/maxstd\r\n",
        "    C1[1][2] = -m[1]/maxstd\r\n",
        "    fp_cond = np.dot(C1, fp)\r\n",
        "\r\n",
        "    # to points (n points)\r\n",
        "    m = np.mean(tp[:2], axis=1)\r\n",
        "    C2 = C1.copy()\r\n",
        "    C2[0][2] = -m[0]/maxstd\r\n",
        "    C2[1][2] = -m[1]/maxstd\r\n",
        "    tp_cond = np.dot(C2,tp)\r\n",
        "\r\n",
        "    # After conditioning, points have mean zero, so translation is zero\r\n",
        "    A = np.concatenate((fp_cond[:2], tp_cond[:2]), axis=0)\r\n",
        "    U,S,V = np.linalg.svd(A.T) # As same as Least-square a = (M^T M)^-1 M^T b but more stability\r\n",
        "\r\n",
        "    # Crate B and C matrices as Harley-Zisserman (2:nd ed) p 130. Multiple view computer vision\r\n",
        "    tmp = V[:2].T\r\n",
        "    B = tmp[:2]\r\n",
        "    C = tmp[2:4]\r\n",
        "\r\n",
        "    tmp2 = np.concatenate((np.dot(C, np.linalg.pinv(B)),np.zeros((2,1))), axis=1)\r\n",
        "    H = np.vstack((tmp2, [0,0,1]))\r\n",
        "\r\n",
        "    #decondition\r\n",
        "    H = np.dot(np.linalg.inv(C2), np.dot(H,C1))\r\n",
        "\r\n",
        "    #normalization and return\r\n",
        "    return H/H[2,2]"
      ],
      "outputs": [],
      "metadata": {
        "id": "J6dyVD24AO5G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 style = \"text-align: center\">\n",
        "Homography matrix from point set\n",
        "</h1>\n",
        "\n",
        "<h2 style = \"text-align: center\">\n",
        "\n",
        "$$\n",
        "    Ma=b, a= \\left( M^{T}M \\right)^{-1} M^T b\n",
        "$$\n",
        "\n",
        "$$\n",
        "    \\left[\n",
        "        \\begin{matrix}\n",
        "            m_{x1}&&m_{y1}&&1&&0&&0&&0&&-m_{x1}n_{x1}&&-m_{y1}n_{x1}\\\\\n",
        "            0&&0&&0&&m_{x1}&&m_{y1}&&1&&-m_{x1}n_{y1}&&-m_{y1}n_{y1}\\\\\n",
        "            m_{x2}&&m_{y2}&&1&&0&&0&&0&&-m_{x2}n_{x2}&&-m_{y2}n_{x2}\\\\\n",
        "            0&&0&&0&&m_{x2}&&m_{y2}&&1&&-m_{x2}n_{y2}&&-m_{y2}n_{y2}\\\\\n",
        "            m_{x3}&&m_{y3}&&1&&0&&0&&0&&-m_{x3}n_{x3}&&-m_{y3}n_{x3}\\\\\n",
        "            0&&0&&0&&m_{x3}&&m_{y3}&&1&&-m_{x3}n_{y3}&&-m_{y3}n_{y3}\\\\\n",
        "            m_{x4}&&m_{y4}&&1&&0&&0&&0&&-m_{x4}n_{x4}&&-m_{y4}n_{x4}\\\\\n",
        "            0&&0&&0&&m_{x4}&&m_{y4}&&1&&-m_{x4}n_{y4}&&-m_{y4}n_{y4}\\\\\n",
        "        \\end{matrix}\n",
        "    \\right]\n",
        "\n",
        "    \\left[\n",
        "        \\begin{matrix}\n",
        "            h_{00}\\\\\n",
        "            h_{01}\\\\\n",
        "            h_{02}\\\\\n",
        "            h_{10}\\\\\n",
        "            h_{11}\\\\\n",
        "            h_{12}\\\\\n",
        "            h_{20}\\\\\n",
        "            h_{21}\n",
        "        \\end{matrix}\n",
        "    \\right]\n",
        "    =\n",
        "    \\left[\n",
        "        \\begin{matrix}\n",
        "            n_{x1}\\\\\n",
        "            n_{y1}\\\\\n",
        "            n_{x2}\\\\\n",
        "            n_{y2}\\\\\n",
        "            n_{x3}\\\\\n",
        "            n_{y3}\\\\\n",
        "            n_{x4}\\\\\n",
        "            n_{y4}\n",
        "            \n",
        "        \\end{matrix}\n",
        "    \\right]\n",
        "$$\n",
        "\n",
        "after standardization\n",
        "\n",
        "$$\n",
        "    \\left[\n",
        "        \\begin{matrix}\n",
        "            -x_1&&-y_1&&-1&&0&&0&&0&&x_1x'_1&&y_1x_1&&x'_1\\\\\n",
        "            0&&0&&0&&-x_1&&-y_1&&-1&&x_1y'_1&&y_1y'_1&&y'_1\\\\\n",
        "            -x_2&&-y_2&&-1&&0&&0&&0&&x_2x'_2&&y_2x_2&&x'_2\\\\\n",
        "            0&&0&&0&&-x_2&&-y_2&&-1&&x_2y'_2&&y_2y'_2&&y'_2\\\\\n",
        "            -x_3&&-y_3&&-1&&0&&0&&0&&x_3x'_3&&y_3x_3&&x'_3\\\\\n",
        "            0&&0&&0&&-x_3&&-y_3&&-1&&x_3y'_3&&y_3y'_3&&y'_3\\\\\n",
        "            -x_4&&-y_4&&-1&&0&&0&&0&&x_4x'_4&&y_4x_4&&x'_4\\\\\n",
        "            0&&0&&0&&-x_4&&-y_4&&-4&&x_4y'_4&&y_4y'_4&&y'_4\\\\\n",
        "        \\end{matrix}\n",
        "    \\right]\n",
        "    \\left[\n",
        "        \\begin{matrix}\n",
        "            h_{00}\\\\\n",
        "            h_{01}\\\\\n",
        "            h_{02}\\\\\n",
        "            h_{10}\\\\\n",
        "            h_{11}\\\\\n",
        "            h_{12}\\\\\n",
        "            h_{20}\\\\\n",
        "            h_{21}\\\\\n",
        "            h_{22}\n",
        "        \\end{matrix}\n",
        "    \\right]\n",
        "    = 0\n",
        "$$\n",
        "\n",
        "</h2>"
      ],
      "metadata": {
        "id": "UQyZnWSiAO5I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def H_from_points(fp, tp) :\r\n",
        "    \"\"\"Find homography matrix tp(n) is projective transform of fp(m)\"\"\"\r\n",
        "\r\n",
        "    if fp.shape != tp.shape :\r\n",
        "        raise RuntimeError('Number of points do not match')\r\n",
        "\r\n",
        "    # Preconditioning points -> normalization, standardization\r\n",
        "    # from points (m points)\r\n",
        "    m = np.mean(fp[:2], axis=1)\r\n",
        "    maxstd = max(np.std(fp[:2], axis=1)) + 1e-9\r\n",
        "    C1 = np.diag([1/maxstd, 1/maxstd, 1])\r\n",
        "    C1[0][2] = -m[0]/maxstd\r\n",
        "    C1[1][2] = -m[1]/maxstd\r\n",
        "    fp = np.dot(C1, fp)\r\n",
        "\r\n",
        "    # to points (n points)\r\n",
        "    m = np.mean(tp[:2], axis=1)\r\n",
        "    maxstd = max(np.std(tp[:2], axis=1)) + 1e-9\r\n",
        "    C2 = np.diag([1/maxstd, 1/maxstd, 1])\r\n",
        "    C2[0][2] = -m[0]/maxstd\r\n",
        "    C2[1][2] = -m[1]/maxstd\r\n",
        "    tp = np.dot(C2,tp)\r\n",
        "\r\n",
        "    # create matrix for linear method, 2 rows for each correpondence pair\r\n",
        "\r\n",
        "    nbr_correspondences = fp.shape[1]\r\n",
        "    A = np.zeros((2*nbr_correspondences, 9))\r\n",
        "    for i in range(nbr_correspondences) :\r\n",
        "        A[2*i] = [-fp[0][i], -fp[1][i], -1, 0, 0, 0, tp[0][i]*fp[0][i], tp[0][i]*fp[1][i], tp[0][i]]\r\n",
        "        A[2*i+1] = [0, 0, 0, -fp[0][i], -fp[1][i], -1, tp[1][i]*fp[0][i], tp[1][i]*fp[1][i], tp[1][i]]\r\n",
        "\r\n",
        "    U,S,V = np.linalg.svd(A)\r\n",
        "    H = V[8].reshape((3,3))\r\n",
        "    \r\n",
        "    #decondition\r\n",
        "    H = np.dot(np.linalg.inv(C2), np.dot(H, C1))\r\n",
        "    \r\n",
        "    #normalization and return\r\n",
        "    return H/H[2,2]"
      ],
      "outputs": [],
      "metadata": {
        "id": "6mR-royEAO5K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "perspective_url = \"https://raw.githubusercontent.com/jbinteam/010723305/main/images/Perspective%20image%20(1).jpg\"\r\n",
        "img = io.imread(perspective_url)\r\n",
        "plt.imshow(img)\r\n",
        "rows, cols = img.shape[:2]\r\n",
        "width = 2000 # A4 Aspect ratio\r\n",
        "height = 2828\r\n",
        "src_points = np.float32([[314, 795], [2328, 323], [592, 3664], [2808, 3572]])\r\n",
        "dst_points = np.float32([[314, 795], [314+width, 795], [314, 795+height] , [314+width, 795+height] ])\r\n",
        "src_homog = make_homogeneous(src_points.T) # Transpose to convert row to column vector\r\n",
        "dst_homog = make_homogeneous(dst_points.T) # Transpose to convert tow to column vector\r\n",
        "print(src_points) # Heterogeneous\r\n",
        "print(src_homog) # Homogeenous\r\n",
        "H = H_from_points(src_homog, dst_homog)\r\n",
        "warped_img = cv2.warpPerspective(img, H, (cols, rows))\r\n",
        "\r\n",
        "fig, axes = plt.subplots(1,2, figsize =(10,10))\r\n",
        "axes[0].imshow(img)\r\n",
        "axes[1].imshow(warped_img)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "id": "prS7T4fbAO5L",
        "outputId": "83b4d969-673e-41c3-b329-1ce0bfafd05b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 style = \"text-align: center\">\n",
        "    RANdom SAmple Consensus <a href=\"https://en.wikipedia.org/wiki/Random_sample_consensus\">(RANSAC)</a>\n",
        "</h1>\n",
        "<div style=\"width:500px; margin:0 auto;\">\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/de/Fitted_line.svg/1024px-Fitted_line.svg.png\">\n",
        "</div>"
      ],
      "metadata": {
        "id": "0i3R06dDAO5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 style = \"text-align: center\">\n",
        "Example implementation code from <a href = https://scipy-cookbook.readthedocs.io/items/RANSAC.html?highlight=ransac> scipy ransac</a>\n",
        "</h2>"
      ],
      "metadata": {
        "id": "D7yAYpHSAO5N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy\r\n",
        "import scipy # use numpy if scipy unavailable\r\n",
        "import scipy.linalg # use numpy if scipy unavailable\r\n",
        "\r\n",
        "## Copyright (c) 2004-2007, Andrew D. Straw. All rights reserved.\r\n",
        "\r\n",
        "## Redistribution and use in source and binary forms, with or without\r\n",
        "## modification, are permitted provided that the following conditions are\r\n",
        "## met:\r\n",
        "\r\n",
        "##     * Redistributions of source code must retain the above copyright\r\n",
        "##       notice, this list of conditions and the following disclaimer.\r\n",
        "\r\n",
        "##     * Redistributions in binary form must reproduce the above\r\n",
        "##       copyright notice, this list of conditions and the following\r\n",
        "##       disclaimer in the documentation and/or other materials provided\r\n",
        "##       with the distribution.\r\n",
        "\r\n",
        "##     * Neither the name of the Andrew D. Straw nor the names of its\r\n",
        "##       contributors may be used to endorse or promote products derived\r\n",
        "##       from this software without specific prior written permission.\r\n",
        "\r\n",
        "## THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\r\n",
        "## \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\r\n",
        "## LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\r\n",
        "## A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\r\n",
        "## OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\r\n",
        "## SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\r\n",
        "## LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\r\n",
        "## DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\r\n",
        "## THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\r\n",
        "## (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\r\n",
        "## OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\r\n",
        "\r\n",
        "def ransac(data,model,n,k,t,d,debug=False,return_all=False):\r\n",
        "    \"\"\"fit model parameters to data using the RANSAC algorithm\r\n",
        "    \r\n",
        "This implementation written from pseudocode found at\r\n",
        "http://en.wikipedia.org/w/index.php?title=RANSAC&oldid=116358182\r\n",
        "\r\n",
        "{{{\r\n",
        "Given:\r\n",
        "    data - a set of observed data points\r\n",
        "    model - a model that can be fitted to data points\r\n",
        "    n - the minimum number of data values required to fit the model\r\n",
        "    k - the maximum number of iterations allowed in the algorithm\r\n",
        "    t - a threshold value for determining when a data point fits a model\r\n",
        "    d - the number of close data values required to assert that a model fits well to data\r\n",
        "Return:\r\n",
        "    bestfit - model parameters which best fit the data (or nil if no good model is found)\r\n",
        "iterations = 0\r\n",
        "bestfit = nil\r\n",
        "besterr = something really large\r\n",
        "while iterations < k {\r\n",
        "    maybeinliers = n randomly selected values from data\r\n",
        "    maybemodel = model parameters fitted to maybeinliers\r\n",
        "    alsoinliers = empty set\r\n",
        "    for every point in data not in maybeinliers {\r\n",
        "        if point fits maybemodel with an error smaller than t\r\n",
        "             add point to alsoinliers\r\n",
        "    }\r\n",
        "    if the number of elements in alsoinliers is > d {\r\n",
        "        % this implies that we may have found a good model\r\n",
        "        % now test how good it is\r\n",
        "        bettermodel = model parameters fitted to all points in maybeinliers and alsoinliers\r\n",
        "        thiserr = a measure of how well model fits these points\r\n",
        "        if thiserr < besterr {\r\n",
        "            bestfit = bettermodel\r\n",
        "            besterr = thiserr\r\n",
        "        }\r\n",
        "    }\r\n",
        "    increment iterations\r\n",
        "}\r\n",
        "return bestfit\r\n",
        "}}}\r\n",
        "\"\"\"\r\n",
        "    iterations = 0\r\n",
        "    bestfit = None\r\n",
        "    besterr = numpy.inf\r\n",
        "    best_inlier_idxs = None\r\n",
        "    while iterations < k:\r\n",
        "        maybe_idxs, test_idxs = random_partition(n,data.shape[0])\r\n",
        "        maybeinliers = data[maybe_idxs,:]\r\n",
        "        test_points = data[test_idxs]\r\n",
        "        maybemodel = model.fit(maybeinliers)\r\n",
        "        test_err = model.get_error( test_points, maybemodel)\r\n",
        "        also_idxs = test_idxs[test_err < t] # select indices of rows with accepted points\r\n",
        "        alsoinliers = data[also_idxs,:]\r\n",
        "        if debug:\r\n",
        "            print ('test_err.min()',test_err.min())\r\n",
        "            print ('test_err.max()',test_err.max())\r\n",
        "            print ('numpy.mean(test_err)',numpy.mean(test_err))\r\n",
        "            print ('iteration %d:len(alsoinliers) = %d'%(\r\n",
        "                iterations,len(alsoinliers)))\r\n",
        "        if len(alsoinliers) > d:\r\n",
        "            betterdata = numpy.concatenate( (maybeinliers, alsoinliers) )\r\n",
        "            bettermodel = model.fit(betterdata)\r\n",
        "            better_errs = model.get_error( betterdata, bettermodel)\r\n",
        "            thiserr = numpy.mean( better_errs )\r\n",
        "            if thiserr < besterr:\r\n",
        "                bestfit = bettermodel\r\n",
        "                besterr = thiserr\r\n",
        "                best_inlier_idxs = numpy.concatenate( (maybe_idxs, also_idxs) )\r\n",
        "        iterations+=1\r\n",
        "    if bestfit is None:\r\n",
        "        raise ValueError(\"did not meet fit acceptance criteria\")\r\n",
        "    if return_all:\r\n",
        "        return bestfit, {'inliers':best_inlier_idxs}\r\n",
        "    else:\r\n",
        "        return bestfit\r\n",
        "\r\n",
        "def random_partition(n,n_data):\r\n",
        "    \"\"\"return n random rows of data (and also the other len(data)-n rows)\"\"\"\r\n",
        "    all_idxs = numpy.arange( n_data )\r\n",
        "    numpy.random.shuffle(all_idxs)\r\n",
        "    idxs1 = all_idxs[:n]\r\n",
        "    idxs2 = all_idxs[n:]\r\n",
        "    return idxs1, idxs2\r\n",
        "\r\n",
        "class LinearLeastSquaresModel:\r\n",
        "    \"\"\"linear system solved using linear least squares\r\n",
        "\r\n",
        "    This class serves as an example that fulfills the model interface\r\n",
        "    needed by the ransac() function.\r\n",
        "    \r\n",
        "    \"\"\"\r\n",
        "    def __init__(self,input_columns,output_columns,debug=False):\r\n",
        "        self.input_columns = input_columns\r\n",
        "        self.output_columns = output_columns\r\n",
        "        self.debug = debug\r\n",
        "    def fit(self, data):\r\n",
        "        A = numpy.vstack([data[:,i] for i in self.input_columns]).T\r\n",
        "        B = numpy.vstack([data[:,i] for i in self.output_columns]).T\r\n",
        "        x,resids,rank,s = scipy.linalg.lstsq(A,B)\r\n",
        "        return x\r\n",
        "    def get_error( self, data, model):\r\n",
        "        A = numpy.vstack([data[:,i] for i in self.input_columns]).T\r\n",
        "        B = numpy.vstack([data[:,i] for i in self.output_columns]).T\r\n",
        "        B_fit = scipy.dot(A,model)\r\n",
        "        err_per_point = numpy.sum((B-B_fit)**2,axis=1) # sum squared error per row\r\n",
        "        return err_per_point\r\n",
        "        \r\n",
        "def test():\r\n",
        "    # generate perfect input data\r\n",
        "\r\n",
        "    n_samples = 500\r\n",
        "    n_inputs = 1\r\n",
        "    n_outputs = 1\r\n",
        "    A_exact = 20*numpy.random.random((n_samples,n_inputs) )\r\n",
        "    perfect_fit = 60*numpy.random.normal(size=(n_inputs,n_outputs) ) # the model\r\n",
        "    B_exact = scipy.dot(A_exact,perfect_fit)\r\n",
        "    assert B_exact.shape == (n_samples,n_outputs)\r\n",
        "\r\n",
        "    # add a little gaussian noise (linear least squares alone should handle this well)\r\n",
        "    A_noisy = A_exact + numpy.random.normal(size=A_exact.shape )\r\n",
        "    B_noisy = B_exact + numpy.random.normal(size=B_exact.shape )\r\n",
        "\r\n",
        "    if 1:\r\n",
        "        # add some outliers\r\n",
        "        n_outliers = 100\r\n",
        "        all_idxs = numpy.arange( A_noisy.shape[0] )\r\n",
        "        numpy.random.shuffle(all_idxs)\r\n",
        "        outlier_idxs = all_idxs[:n_outliers]\r\n",
        "        non_outlier_idxs = all_idxs[n_outliers:]\r\n",
        "        A_noisy[outlier_idxs] =  20*numpy.random.random((n_outliers,n_inputs) )\r\n",
        "        B_noisy[outlier_idxs] = 50*numpy.random.normal(size=(n_outliers,n_outputs) )\r\n",
        "\r\n",
        "    # setup model\r\n",
        "\r\n",
        "    all_data = numpy.hstack( (A_noisy,B_noisy) )\r\n",
        "    input_columns = range(n_inputs) # the first columns of the array\r\n",
        "    output_columns = [n_inputs+i for i in range(n_outputs)] # the last columns of the array\r\n",
        "    debug = False\r\n",
        "    model = LinearLeastSquaresModel(input_columns,output_columns,debug=debug)\r\n",
        "\r\n",
        "    linear_fit,resids,rank,s = scipy.linalg.lstsq(all_data[:,input_columns],\r\n",
        "                                                  all_data[:,output_columns])\r\n",
        "\r\n",
        "    # run RANSAC algorithm\r\n",
        "    ransac_fit, ransac_data = ransac(all_data,model,\r\n",
        "                                     50, 1000, 7e3, 300, # misc. parameters\r\n",
        "                                     debug=debug,return_all=True)\r\n",
        "    if 1:\r\n",
        "        import pylab\r\n",
        "\r\n",
        "        sort_idxs = numpy.argsort(A_exact[:,0])\r\n",
        "        A_col0_sorted = A_exact[sort_idxs] # maintain as rank-2 array\r\n",
        "\r\n",
        "        if 1:\r\n",
        "            pylab.plot( A_noisy[:,0], B_noisy[:,0], 'k.', label='data' )\r\n",
        "            pylab.plot( A_noisy[ransac_data['inliers'],0], B_noisy[ransac_data['inliers'],0], 'bx', label='RANSAC data' )\r\n",
        "        else:\r\n",
        "            pylab.plot( A_noisy[non_outlier_idxs,0], B_noisy[non_outlier_idxs,0], 'k.', label='noisy data' )\r\n",
        "            pylab.plot( A_noisy[outlier_idxs,0], B_noisy[outlier_idxs,0], 'r.', label='outlier data' )\r\n",
        "        pylab.plot( A_col0_sorted[:,0],\r\n",
        "                    numpy.dot(A_col0_sorted,ransac_fit)[:,0],\r\n",
        "                    label='RANSAC fit' )\r\n",
        "        pylab.plot( A_col0_sorted[:,0],\r\n",
        "                    numpy.dot(A_col0_sorted,perfect_fit)[:,0],\r\n",
        "                    label='exact system' )\r\n",
        "        pylab.plot( A_col0_sorted[:,0],\r\n",
        "                    numpy.dot(A_col0_sorted,linear_fit)[:,0],\r\n",
        "                    label='linear fit' )\r\n",
        "        pylab.legend()\r\n",
        "        pylab.show()\r\n",
        "\r\n",
        "if __name__=='__main__':\r\n",
        "    pass\r\n",
        "    # test()\r\n",
        "    "
      ],
      "outputs": [],
      "metadata": {
        "id": "CQ6gC6hNAO5N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class RansacModel(object) :\r\n",
        "    \"\"\"Class for homography fit with scipy ransac\"\"\"\r\n",
        "    def __init__(self, debug = False):\r\n",
        "        self.debug = debug\r\n",
        "\r\n",
        "    def fit(self, data) :\r\n",
        "        \"\"\"Homography  fitting to four selected correpondences\"\"\"\r\n",
        "        data = data.T # Tranpose in order to convert row to column vector\r\n",
        "\r\n",
        "        # from points (m points)\r\n",
        "        fp = data[:3, :4]\r\n",
        "        # to points (n points)\r\n",
        "        tp = data[3:, :4]\r\n",
        "\r\n",
        "        return H_from_points(fp, tp)\r\n",
        "    \r\n",
        "    def get_error(self, data, H) :\r\n",
        "        \"\"\"Apply homography to all correspondences, then calculate error for each point.\"\"\"\r\n",
        "        data = data.T\r\n",
        "        \r\n",
        "        # from points (m points)\r\n",
        "        fp = data[:3]\r\n",
        "        # to points (n points)\r\n",
        "        tp = data[3:]\r\n",
        "\r\n",
        "        #transform fp with homography\r\n",
        "        fp_transformed = np.dot(H, fp)\r\n",
        "\r\n",
        "        #normalized homogeneous coordinate\r\n",
        "        for i in range(3) :\r\n",
        "            fp_transformed[i] /= fp_transformed[2] # divide by the last row\r\n",
        "        \r\n",
        "        #return error per point\r\n",
        "        error = np.sqrt(np.sum((tp-fp_transformed)**2, axis=0) ) # Euclidean distance, Reprojection error\r\n",
        "        return error\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "xc7IJxhAAO5Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def H_from_ransac(fp, tp, model, maxiter=1000, match_threshold = 10) :\n",
        "    \"\"\"Homography matrix from RANSAC robust estimator\"\"\"\n",
        "    data = np.vstack((fp,tp))\n",
        "    H, ransac_data = ransac(data.T, model, 4, maxiter, match_threshold, 10, return_all=True)\n",
        "    return H, ransac_data['inliers']"
      ],
      "outputs": [],
      "metadata": {
        "id": "EDCWhdaTAO5S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "left_img_url = \"https://raw.githubusercontent.com/jbinteam/010723305/main/images/left-mountain.png\"\n",
        "right_img_url = \"https://raw.githubusercontent.com/jbinteam/010723305/main/images/right-moutain.png\"\n",
        "left_img = io.imread(left_img_url)\n",
        "right_img = io.imread(right_img_url)\n",
        "\n",
        "left_gray = cv2.cvtColor(left_img, cv2.COLOR_BGR2GRAY)\n",
        "right_gray = cv2.cvtColor(right_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "imshow_compare(left_img, right_img)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "V1kQ81vVAO5T",
        "outputId": "e14c9635-f1dc-438e-ffe0-f31ae49eca26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 style = \"text-align: center\">\n",
        "    Sift feature detector and Brute force matcher\n",
        "</h2>\n",
        "\n",
        "<h2 style = \"text-align: center\">\n",
        "    We need to extract feature location out from good_matches to use with H_from_ransac. <br>\n",
        "    Please refer to <a href =\"https://docs.opencv.org/4.5.3/d2/d29/classcv_1_1KeyPoint.html\"> KeyPoint </a> and <a href = \"https://docs.opencv.org/master/d4/de0/classcv_1_1DMatch.html\"> DMatch </a> for opencv keypoint and descriptor data structure respectively\n",
        "</h2>"
      ],
      "metadata": {
        "id": "UBMykeBwAO5T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Feature extraction -> feature detection, descriptor extraction\r\n",
        "sift = cv2.SIFT_create()\r\n",
        "\r\n",
        "left_kpts, left_desc = sift.detectAndCompute(left_gray,None)\r\n",
        "right_kpts, right_desc = sift.detectAndCompute(right_gray,None)\r\n",
        "\r\n",
        "# Feature descriptor matching & Distance ratio test\r\n",
        "bf = cv2.BFMatcher()\r\n",
        "matches = bf.knnMatch(left_desc, right_desc, k=2)\r\n",
        "\r\n",
        "good_matches = list()\r\n",
        "\r\n",
        "for m, n in matches :\r\n",
        "    if m.distance < 0.7*n.distance :\r\n",
        "        good_matches.append(m)\r\n",
        "\r\n",
        "print(type(good_matches[0]))\r\n",
        "\r\n",
        "m = list()\r\n",
        "n = list()\r\n",
        "\r\n",
        "\r\n",
        "# Prepare matched feature location data to use with H_from_ransac\r\n",
        "for matched in good_matches :\r\n",
        "    fp_idx = matched.queryIdx\r\n",
        "    tp_idx = matched.trainIdx\r\n",
        "    (xfp, yfp) = left_kpts[fp_idx].pt\r\n",
        "    (xtp, ytp) = right_kpts[tp_idx].pt\r\n",
        "\r\n",
        "    m.append((xfp, yfp))\r\n",
        "    n.append((xtp, ytp))\r\n",
        "\r\n",
        "m_np = np.asarray(m, dtype=np.float32)\r\n",
        "n_np = np.asarray(n, dtype=np.float32)\r\n",
        "\r\n",
        "m_homog = make_homogeneous(m_np.T)\r\n",
        "n_homog = make_homogeneous(n_np.T)\r\n",
        "\r\n",
        "model = RansacModel()\r\n",
        "H, inliers = H_from_ransac(n_homog, m_homog, model) # Homography from right to left\r\n",
        "        \r\n",
        "rows, cols = left_img.shape[:2]\r\n",
        "warped_img = cv2.warpPerspective(right_img,H, (2*cols, 2*rows))\r\n",
        "imshow_compare(left_img, warped_img)\r\n"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "SasCNKuMAO5T",
        "outputId": "c20425bf-cc35-474c-ba9f-02e8ac019bfd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "warped_img[0:rows, 0:cols] = left_img\r\n",
        "plt.figure(figsize=(20,20))\r\n",
        "plt.imshow(warped_img)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        },
        "id": "YRzylenKAO5U",
        "outputId": "8d1d3f5c-cf80-4118-87a9-6abcb6e6867b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "grayscale = cv2.cvtColor(warped_img, cv2.COLOR_RGB2GRAY)\r\n",
        "mask = cv2.threshold(grayscale, 0, 255, cv2.THRESH_BINARY)[1]\r\n",
        "plt.imshow(mask, cmap = 'gray')\r\n",
        "\r\n",
        "# find contour inside mask \r\n",
        "contour, hier = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\r\n",
        "\r\n",
        "# get contour with maximum area\r\n",
        "max_area_contour = max(contour, key=cv2.contourArea)\r\n",
        "\r\n",
        "# create bounding box\r\n",
        "(x, y, w, h) = cv2.boundingRect(max_area_contour)\r\n",
        "\r\n",
        "result = warped_img.copy()\r\n",
        "result = result[0:h, 0:w]\r\n",
        "plt.figure()\r\n",
        "imshow_compare(left_img, right_img)\r\n",
        "plt.figure(figsize=(20,20))\r\n",
        "plt.imshow(result)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3LIneHxMAO5V",
        "outputId": "9c9de577-0abd-4430-f4df-282a1c78067d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 style = \"text-align: center\">\n",
        "    Panorama: OpenCV implementation\n",
        "</h1>"
      ],
      "metadata": {
        "id": "_CCONVkJAO5V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ref_img_url = \"https://raw.githubusercontent.com/jbinteam/010723305/main/images/left-mountain.png\"\r\n",
        "query_img_url = \"https://raw.githubusercontent.com/jbinteam/010723305/main/images/right-moutain.png\"\r\n",
        "\r\n",
        "ref_img = io.imread(ref_img_url)\r\n",
        "ref_gray = cv2.cvtColor(ref_img, cv2.COLOR_BGR2GRAY)\r\n",
        "\r\n",
        "query_img = io.imread(query_img_url)\r\n",
        "query_gray = cv2.cvtColor(query_img, cv2.COLOR_BGR2GRAY)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Tk5heHGyAO5V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sift = cv2.SIFT_create()"
      ],
      "outputs": [],
      "metadata": {
        "id": "wbOLwSfaAO5W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ref_kpts, ref_desc = sift.detectAndCompute(ref_gray, None)\r\n",
        "query_kpts, query_desc = sift.detectAndCompute(query_gray, None)"
      ],
      "outputs": [],
      "metadata": {
        "id": "cqA8wzBXAO5W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "bf = cv2.BFMatcher()\r\n",
        "matches = bf.knnMatch(ref_desc, query_desc, k =2)\r\n",
        "\r\n",
        "good_matches = list()\r\n",
        "good_matches_list = list()\r\n",
        "\r\n",
        "for m, n in matches :\r\n",
        "    if m.distance < 0.7*n.distance :\r\n",
        "        good_matches.append(m)\r\n",
        "        good_matches_list.append([m])\r\n",
        "\r\n",
        "ratio_matched_img = cv2.drawMatchesKnn(ref_img, ref_kpts, query_img, query_kpts,good_matches_list , None, flags=2)\r\n",
        "plt.figure(figsize=(20,20))\r\n",
        "plt.imshow(ratio_matched_img)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "ZTdLZOeLAO5W",
        "outputId": "076da474-d4fa-424a-c315-b35a0470132c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 style = \"text-align: center\">\n",
        "    OpenCV also has built-in function form Homography estimation with RANSAC scheme <br>\n",
        "    That is <a href = \"https://docs.opencv.org/4.5.3/d9/d0c/group__calib3d.html#ga4abc2ece9fab9398f2e560d53c8c9780\"> findHomography() </a> which support many solving method\n",
        "</h2>"
      ],
      "metadata": {
        "id": "8S1N737XAO5W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def crop_image(ref_img, query_img, H) : # Warp and crop\r\n",
        "    rows, cols = ref_img.shape[:2]\r\n",
        "    warped_img = cv2.warpPerspective(query_img, H, (2*cols, 2*rows))\r\n",
        "    warped_img[0:rows, 0:cols] = ref_img\r\n",
        "    grayscale = cv2.cvtColor(warped_img, cv2.COLOR_RGB2GRAY)\r\n",
        "    mask = cv2.threshold(grayscale, 0, 255, cv2.THRESH_BINARY)[1]\r\n",
        "    # find contour inside mask \r\n",
        "    contour, hier = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\r\n",
        "\r\n",
        "    # get contour with maximum area\r\n",
        "    max_area_contour = max(contour, key=cv2.contourArea)\r\n",
        "\r\n",
        "    # create bounding box\r\n",
        "    (x, y, w, h) = cv2.boundingRect(max_area_contour)\r\n",
        "\r\n",
        "    result = warped_img[:h, :w]\r\n",
        "    return result"
      ],
      "outputs": [],
      "metadata": {
        "id": "LYLBfNw_AO5X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "MIN_MATCH_NUMBER = 10\r\n",
        "\r\n",
        "if len(good_matches) > MIN_MATCH_NUMBER :\r\n",
        "    print('Enough matched feature')\r\n",
        "    tp = np.float32([ ref_kpts[m.queryIdx].pt for m in good_matches ]).reshape(-1,1,2)\r\n",
        "    fp = np.float32([ query_kpts[m.trainIdx].pt for m in good_matches ]).reshape(-1,1,2)\r\n",
        "    \r\n",
        "    H, inlier_masks = cv2.findHomography(fp, tp, cv2.RANSAC, 10.0)\r\n",
        "    ransac_img = cv2.drawMatchesKnn(ref_img, ref_kpts, query_img, query_kpts, good_matches_list, None, flags=2, matchesMask=inlier_masks)\r\n",
        "    plt.figure(figsize=(20,20))\r\n",
        "    plt.imshow(ransac_img)\r\n",
        "\r\n",
        "    result = crop_image(ref_img, query_img, H)\r\n",
        "    plt.figure(figsize=(20,20))\r\n",
        "    plt.imshow(result)\r\n",
        "\r\n",
        "else :\r\n",
        "    print('Not enough for Homography estimation')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FE8NJz0fAO5X",
        "outputId": "b1a32cc2-1f17-410f-b5bf-415c0a8a6240"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 style = \"text-align: center\">\n",
        "    Object detection: OpenCV Implementation\n",
        "</h1>\n",
        "<h2 style= \"text-align: center\">\n",
        "    We can also use feature matching together with homography RANSAC scheme to build simple object detection as shown below:\n",
        "</h>"
      ],
      "metadata": {
        "id": "idyOlZ1kAO5X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def preprocessing(img) :\r\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n",
        "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n",
        "    return (img, img_gray)"
      ],
      "outputs": [],
      "metadata": {
        "id": "-o2dUFY6AO5X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "template_img_url = \"https://raw.githubusercontent.com/jbinteam/010723305/main/images/template.png\"\r\n",
        "query_img_url = \"https://raw.githubusercontent.com/jbinteam/010723305/main/images/query.png\"\r\n",
        "query_img_far_url = \"https://raw.githubusercontent.com/jbinteam/010723305/main/images/query-far.png\"\r\n",
        "\r\n",
        "template_img = io.imread(template_img_url)\r\n",
        "template_img, template_gray = preprocessing(template_img)\r\n",
        "\r\n",
        "query_img = io.imread(query_img_url)\r\n",
        "query_img, query_gray = preprocessing(query_img)\r\n",
        "\r\n",
        "query_far_img = io.imread(query_img_far_url)\r\n",
        "query_far_img, query_far_gray = preprocessing(query_far_img)\r\n",
        "\r\n",
        "imshow_compare(template_img, query_img)\r\n",
        "imshow_compare(template_img, query_far_img)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ifXvs1uLAO5Y",
        "outputId": "e5a4f09f-c836-4afe-bf6d-2146bd32bc11"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sift = cv2.SIFT_create()\r\n",
        "bf = cv2.BFMatcher()"
      ],
      "outputs": [],
      "metadata": {
        "id": "bz6jCcq9AO5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 style= \"text-align: center\">\n",
        "    In order to transform point with homography matrix please refer to\n",
        "    <a href = \"https://docs.opencv.org/4.5.3/d2/de8/group__core__array.html#gad327659ac03e5fd6894b90025e6900a7\"> perspectiveTransform</a>\n",
        "</h2>"
      ],
      "metadata": {
        "id": "LTw7Ga2sAO5Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def feature_object_detection(template_img, template_gray, query_img, query_gray, min_match_number) :\r\n",
        "    template_kpts, template_desc = sift.detectAndCompute(template_gray, None)\r\n",
        "    query_kpts, query_desc = sift.detectAndCompute(query_gray, None)\r\n",
        "    matches = bf.knnMatch(template_desc, query_desc, k=2)\r\n",
        "    good_matches = list()\r\n",
        "    good_matches_list = list()\r\n",
        "    for m, n in matches :\r\n",
        "        if m.distance < 0.7*n.distance :\r\n",
        "            good_matches.append(m)\r\n",
        "            good_matches_list.append([m])\r\n",
        "    \r\n",
        "    if len(good_matches) > min_match_number :\r\n",
        "        src_pts = np.float32([ template_kpts[m.queryIdx].pt for m in good_matches ]).reshape(-1,1,2)\r\n",
        "        dst_pts = np.float32([ query_kpts[m.trainIdx].pt for m in good_matches ]).reshape(-1,1,2)\r\n",
        "\r\n",
        "        H, inlier_masks = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 10.0) # H RANSAC\r\n",
        "        # get the bounding box around template image\r\n",
        "        h, w = template_img.shape[:2]\r\n",
        "        template_box = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1,1,2)\r\n",
        "        transformed_box = cv2.perspectiveTransform(template_box, H)\r\n",
        "\r\n",
        "        detected_img = cv2.polylines(query_img, [np.int32(transformed_box)], True, (255,0,0), 3, cv2.LINE_AA)\r\n",
        "        drawmatch_img = cv2.drawMatchesKnn(template_img, template_kpts, detected_img, query_kpts, good_matches_list, None, flags=2, matchesMask=inlier_masks)\r\n",
        "\r\n",
        "        return detected_img, drawmatch_img\r\n",
        "    else :\r\n",
        "        print('Keypoints not enough')\r\n",
        "        return\r\n",
        "    "
      ],
      "outputs": [],
      "metadata": {
        "id": "kmvt8UU-AO5Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "detected, drawmatch =  feature_object_detection(template_img, template_gray, query_img, query_gray, 10)\r\n",
        "plt.figure(figsize=(20,20))\r\n",
        "plt.imshow(detected)\r\n",
        "plt.figure(figsize=(20,20))\r\n",
        "plt.imshow(drawmatch)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Tx4SE_HoAO5Z",
        "outputId": "94f043f7-a7ee-444c-923e-f6a979248fff"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "detected, drawmatch =  feature_object_detection(template_img, template_gray, query_far_img, query_far_gray, 10)\r\n",
        "plt.figure(figsize=(20,20))\r\n",
        "plt.imshow(detected)\r\n",
        "plt.figure(figsize=(20,20))\r\n",
        "plt.imshow(drawmatch)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ouhOPp_-AO5b",
        "outputId": "030c224f-2629-4183-d365-56a4e9cda32b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1 style=\"text-align: center\"> Image stitching (Panorama) exercise</h1>"
      ],
      "metadata": {
        "id": "5lOPR5hfAO5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>แบบฝึกหัดที่ 9.2</h2>\n",
        "<h4>วัตถุประสงค์ </h1>\n",
        "\n",
        "- ทักษะการทำ image stitching\n",
        "<h4>โจทย์</h4>\n",
        "\n",
        "- ให้นักศึกษาเขียน code ซอฟต์แวร์นำข้อมูลภาพถ่ายทางอากาศเพื่อการเกษตรนำมาต่อเข้าด้วยกันให้เป็นภาพใหญ่เพียงภาพเดียวด้วยเทคนิด image stitching\n",
        "- ในการนำภาพมาเย็บต่อกันให้ใช้ฟังก์ชัน stitch_and_crop ที่ได้เตรียมไว้ด้านล่าง พร้อมอธิบายการทำงานฟังก์ชันดังกล่าวลงใน google colab\n",
        "- credit <a href=\"https://blog.samaritakis.gr/en/quick-photo-stitching-using-7-aerial-photos-vineyards/\">https://blog.samaritakis.gr/en/quick-photo-stitching-using-7-aerial-photos-vineyards/  </a>\n",
        "\n",
        "- ชุดข้อมูลภาพอยู่ใน <a href = \"https://github.com/jbinteam/010723305/tree/main/images\">https://github.com/jbinteam/010723305/tree/main/images</a><br>\n",
        "<a href = \"https://raw.githubusercontent.com/jbinteam/010723305/main/images/IMG_2010.jpg\">https://raw.githubusercontent.com/jbinteam/010723305/main/images/IMG_2010.jpg</a><br>\n",
        "<a href = \"https://raw.githubusercontent.com/jbinteam/010723305/main/images/IMG_2011.jpg\">https://raw.githubusercontent.com/jbinteam/010723305/main/images/IMG_2011.jpg</a><br>\n",
        "<a href = \"https://raw.githubusercontent.com/jbinteam/010723305/main/images/IMG_2012.jpg\">https://raw.githubusercontent.com/jbinteam/010723305/main/images/IMG_2012.jpg</a><br>\n",
        "<a href = \"https://raw.githubusercontent.com/jbinteam/010723305/main/images/IMG_2013.jpg\">https://raw.githubusercontent.com/jbinteam/010723305/main/images/IMG_2013.jpg</a><br>\n",
        "<a href = \"https://raw.githubusercontent.com/jbinteam/010723305/main/images/IMG_2014.jpg\">https://raw.githubusercontent.com/jbinteam/010723305/main/images/IMG_2014.jpg</a><br>\n",
        "<a href = \"https://raw.githubusercontent.com/jbinteam/010723305/main/images/IMG_2015.jpg\">https://raw.githubusercontent.com/jbinteam/010723305/main/images/IMG_2015.jpg</a><br>\n",
        "<a href = \"https://raw.githubusercontent.com/jbinteam/010723305/main/images/IMG_2016.jpg\">https://raw.githubusercontent.com/jbinteam/010723305/main/images/IMG_2016.jpg</a><br>\n",
        "- ผลลัพธ์ที่คาดหวัง\n",
        "\n",
        "<img src = \"https://raw.githubusercontent.com/jbinteam/010723305/main/images/Stitched.png\" >"
      ],
      "metadata": {
        "id": "bpNqZSrGAO5b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def stitch_and_crop(ref_img, query_img, H) : # Warp and stitch\r\n",
        "    rows, cols = ref_img.shape[:2]\r\n",
        "    warped_img = cv2.warpPerspective(query_img, H, (2*cols, 2*rows))\r\n",
        "    enlarge_ref_img = np.zeros((2*rows, 2*cols, 3), dtype=np.uint8)\r\n",
        "    enlarge_ref_img[:rows, :cols] = ref_img\r\n",
        "    warped_gray = cv2.cvtColor(warped_img, cv2.COLOR_RGB2GRAY)\r\n",
        "    warped_mask = cv2.threshold(warped_gray, 0, 255, cv2.THRESH_BINARY)[1]\r\n",
        "    segmented_ref_img = cv2.add(warped_img, enlarge_ref_img, mask=np.bitwise_not(warped_mask))\r\n",
        "    result = cv2.add(segmented_ref_img, warped_img)\r\n",
        "\r\n",
        "    grayscale = cv2.cvtColor(result, cv2.COLOR_RGB2GRAY)\r\n",
        "    mask = cv2.threshold(grayscale, 0, 255, cv2.THRESH_BINARY)[1]\r\n",
        "    # # find contour inside mask \r\n",
        "    contour, hier = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\r\n",
        "\r\n",
        "    # # get contour with maximum area\r\n",
        "    max_area_contour = max(contour, key=cv2.contourArea)\r\n",
        "\r\n",
        "    # # create bounding box\r\n",
        "    (x, y, w, h) = cv2.boundingRect(max_area_contour)\r\n",
        "\r\n",
        "    return result[:h, :w]"
      ],
      "outputs": [],
      "metadata": {
        "id": "RZ7RJ-PaAO5c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "img_list = list()\r\n",
        "for i in range(7) :\r\n",
        "\r\n",
        "    img = io.imread('https://raw.githubusercontent.com/jbinteam/010723305/main/images/IMG_201{}.jpg'.format(i))\r\n",
        "    img_list.append(img)\r\n",
        "\r\n",
        "def image_stitching(img_list) :\r\n",
        "    \r\n",
        "    ## coding here ##\r\n",
        "    \r\n",
        "    result = stitch_and_crop(ref_img, query_img, H)\r\n",
        "\r\n",
        "    return result\r\n",
        "\r\n",
        "result = image_stitching(img_list)\r\n",
        "plt.imshow(result)"
      ],
      "outputs": [],
      "metadata": {
        "id": "ESf_KU_KAO5c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "bgm_RKJSITmq"
      }
    }
  ]
}