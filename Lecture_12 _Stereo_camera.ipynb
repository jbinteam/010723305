{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dir = os.getcwd()+'/camera_params/stereo_camera_params/' #Calibration -> Parallel image \n",
    "print(params_dir)\n",
    "# Load camera parameters\n",
    "ret = np.load(params_dir+'ret.npy')\n",
    "K = np.load(params_dir+'K.npy')\n",
    "dist = np.load(params_dir+'dist.npy')\n",
    "focal_length = (K[0,0] + K[1,1])/2\n",
    "\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampling_image(image, reduction_scale) : # Reduce image resolution Pyr lelel\n",
    "    for i in range(0, reduction_scale) :\n",
    "        if len(image.shape) > 2:\n",
    "            row, col = image.shape[:2]\n",
    "        else :\n",
    "            row, col = image.shape\n",
    "        \n",
    "        image = cv2.pyrDown(image,dstsize=(col//2,row//2))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare stereo matching variables\n",
    "#This section student has to do fine tunes by yourself for max_disp\n",
    "win_size = 5\n",
    "min_disparity = -1\n",
    "max_disparity = 63\n",
    "num_disparity = max_disparity - min_disparity #Must be divisible by 16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style = \"text-align: center\">\n",
    "    <a href=\"https://docs.opencv.org/4.5.3/d2/d85/classcv_1_1StereoSGBM.html\">Stereo SemiGlobal Matching (StereoSGBM)</a>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo = cv2.StereoSGBM_create(\n",
    "    minDisparity = min_disparity, \n",
    "    numDisparities = num_disparity,\n",
    "    blockSize = 10,\n",
    "    uniquenessRatio = 1,\n",
    "    speckleWindowSize = 5,\n",
    "    speckleRange = 5,\n",
    "    disp12MaxDiff = 2,\n",
    "    P1 = 8*3*win_size**2,\n",
    "    P2 = 32*3*win_size**2\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style = \"text-align: center\">\n",
    "    Camera Projection matrix\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_cap = cv2.VideoCapture('./videos/stereo/left_output.avi')\n",
    "right_cap = cv2.VideoCapture('./videos/stereo/right_output.avi')\n",
    "\n",
    "ret ,left_img = left_cap.read() # You have to read left and right together for syncing the video frame\n",
    "ret ,right_img = right_cap.read() \n",
    "\n",
    "h, w = left_img.shape[:2]\n",
    "\n",
    "R = np.float64([\n",
    "    [1,0,0],\n",
    "    [0,1,0],\n",
    "    [0,0,1]    \n",
    "])\n",
    "\n",
    "\n",
    "t = np.float64([\n",
    "    [0.1],\n",
    "    [0.0],\n",
    "    [0.0]\n",
    "])\n",
    "\n",
    "R1, R2, P1, P2, Q, validPixROI1, validPixROI2 = cv2.stereoRectify(K, dist, K, dist, (h, w), cv2.Rodrigues(R)[0], t, flags=0)\n",
    "print(Q)\n",
    "\n",
    "#Perspective transformation matrix. This one is coming from https://ags.cs.uni-kl.de/fileadmin/inf_ags/3dcv-ws14-15/3DCV_lec01_camera.pdf\n",
    "Q2 = np.float32([\n",
    "    [1,  0,  0,  -w/2.0],\n",
    "    [0, 1,  0,  -h/2.0],\n",
    "    [0,  0,  -focal_length/1000.0, 0],\n",
    "    [0,  0,  0,  1]\n",
    "])\n",
    "print('Modified Perspective Projection matrix')\n",
    "print(Q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style = \"text-align: center\">\n",
    "    <a href=\"http://www.open3d.org/\">Open3D</a>\n",
    "</h1>\n",
    "<h2 style = \"text-align: center\"> Open3D is the open-source software library for 3D data processing </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init =False\n",
    "\n",
    "# Open3D Visualizer\n",
    "pointcloud_visualizer = o3d.visualization.Visualizer()\n",
    "pointcloud_visualizer.create_window(window_name = \"Pointclouds\",width = 864, height = 480)\n",
    "o3d_pointclouds = o3d.geometry.PointCloud()\n",
    "pointcloud_visualizer.add_geometry(o3d_pointclouds)\n",
    "# Open3D Visualizer\n",
    "\n",
    "#Creating video capture devices\n",
    "left_cap = cv2.VideoCapture('./videos/stereo/left_output.avi')\n",
    "right_cap = cv2.VideoCapture('./videos/stereo/right_output.avi')\n",
    "\n",
    "ret ,left_img = left_cap.read() # You have to read left and right together for syncing the video frame\n",
    "ret ,right_img = right_cap.read() \n",
    "\n",
    "h, w = left_img.shape[:2]\n",
    "\n",
    "#Get the new optimal camera matrix for better undistortion\n",
    "new_camera_matrix, roi = cv2.getOptimalNewCameraMatrix(K, dist, (w,h),1, (w,h))\n",
    "\n",
    "\n",
    "while (left_cap.isOpened() and right_cap.isOpened() ) :\n",
    "    \n",
    "    ret_left, left_img = left_cap.read()\n",
    "    ret_right, right_img = right_cap.read()\n",
    "    \n",
    "    if ret_left and ret_right :\n",
    "\n",
    "        left_img = cv2.cvtColor(left_img, cv2.COLOR_BGR2GRAY)\n",
    "        right_img = cv2.cvtColor(right_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        #Undistort image\n",
    "        left_img_undistorted = cv2.undistort(left_img, K, dist, None, new_camera_matrix)\n",
    "        right_img_undistorted = cv2.undistort(right_img, K, dist, None, new_camera_matrix)\n",
    "        \n",
    "        #Downsampling each image 1 pyramid level in order to improve computational speed\n",
    "        left_img_down = downsampling_image(left_img_undistorted,1)\n",
    "        right_img_down = downsampling_image(right_img_undistorted,1)\n",
    "\n",
    "        disparity_map = stereo.compute(left_img_down, right_img_down) # Range 0-2 -> 8bits 0-255\n",
    "        norm_disp = cv2.normalize(disparity_map, None , alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "\n",
    "        #Reproject point into 3D/Pointclouds\n",
    "        pointclouds = cv2.reprojectImageTo3D(disparity_map, Q2)\n",
    "        #Filter out the point with value 0 or no depth\n",
    "        filtered_map = disparity_map > 0\n",
    "\n",
    "        filtered_clouds = pointclouds[filtered_map]\n",
    "        R = np.float64([\n",
    "            [1,0,0],\n",
    "            [0,-1,0],\n",
    "            [0,0,-1]\n",
    "        ])\n",
    "        \n",
    "        transformed_cloud = np.dot(R, filtered_clouds.T).T\n",
    "        # print(transformed_cloud.shape)\n",
    "        # print('max: {}'.format(transformed_cloud.max()))\n",
    "        # print('min: {}'.format(transformed_cloud.min()))\n",
    "        o3d_pointclouds.points = o3d.utility.Vector3dVector(transformed_cloud)\n",
    "        o3d_pointclouds.remove_non_finite_points()\n",
    "        \n",
    "        if not init :\n",
    "            pointcloud_visualizer.add_geometry(o3d_pointclouds)\n",
    "            init = True\n",
    "        else :\n",
    "            pointcloud_visualizer.update_geometry(o3d_pointclouds)\n",
    "        \n",
    "        pointcloud_visualizer.poll_events()\n",
    "        pointcloud_visualizer.update_renderer()\n",
    "        row, col = norm_disp.shape[:2]\n",
    "        norm_disp = cv2.pyrUp(norm_disp,dstsize=(col*2, row*2))\n",
    "        dist_hsv = cv2.applyColorMap(norm_disp,cv2.COLORMAP_JET)\n",
    "        # Depth estimation base line is 0.1 metre\n",
    "        z = (focal_length * 0.1)/disparity_map\n",
    "        \n",
    "        \n",
    "        \n",
    "        left_right = cv2.hconcat([left_img, right_img])\n",
    "        cv2.imshow('Frame', left_right)\n",
    "        cv2.imshow('Disparity', dist_hsv)\n",
    "        \n",
    "        \n",
    "        if cv2.waitKey(33) & 0xff == 27 :\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "left_cap.release()\n",
    "right_cap.release()\n",
    "pointcloud_visualizer.destroy_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bde8de4267fa2326a064a32ec8bfaf139654fccd7a5afd7688ec5ca48592f22e"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
